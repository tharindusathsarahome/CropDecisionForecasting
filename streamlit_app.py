import streamlit as st
from google import generativeai as genai
from PIL import Image
import time
import re

# --- 1. ‡∂¥‡∑í‡∂ß‡∑î ‡∑É‡∑ê‡∂ö‡∑É‡∑î‡∂∏ ‡∑É‡∑Ñ API ‡∂∫‡∂≠‡∑î‡∂ª ---
st.set_page_config(
    page_title="Plant Disease Analyzer",
    page_icon="üå±",
    layout="centered"
)

try:
    api_key = st.secrets['GEMINI_API_KEY']
    genai.configure(api_key=api_key)
except (KeyError, Exception):
    st.error("GEMINI_API_KEY ‡∑É‡∑ú‡∂∫‡∑è‡∂ú‡∂≠ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö. ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂ë‡∂∫ ‡∂î‡∂∂‡∂ú‡∑ö Streamlit ‡∂ª‡∑Ñ‡∑É‡∑ä ‡∑Ä‡∑ô‡∂≠ ‡∂ë‡∂ö‡∑ä ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.")
    st.stop()

# --- 2. AI ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂¥‡∂Ø‡∑ä‡∂∞‡∂≠‡∑í ‡∂ã‡∂¥‡∂Ø‡∑ô‡∑É‡∑ä ---
IDENTIFICATION_INSTRUCTION = "‡∂î‡∂∂‡∑ö ‡∂ë‡∂ö‡∂∏ ‡∂ö‡∑è‡∂ª‡∑ä‡∂∫‡∂∫ ‡∑Ä‡∂±‡∑ä‡∂±‡∑ö ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ì ‡∂á‡∂≠‡∑í ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫‡∑ö ‡∂á‡∂≠‡∑í ‡∑Å‡∑è‡∂ö‡∂∫‡∑ö ‡∂±‡∂∏ ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω‡∑ô‡∂±‡∑ä ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂∫‡∑í. ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª ‡∂Ω‡∑ô‡∑É ‡∑Å‡∑è‡∂ö‡∂∫‡∑ö ‡∂±‡∂∏ ‡∂¥‡∂∏‡∂´‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±. ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´‡∂∫‡∂ö‡∑ä ‡∂Ω‡∑ô‡∑É: '‡∂ª‡∑ù‡∑É'. ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∂≠ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö‡∑í ‡∂±‡∂∏‡∑ä, '‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∂≠ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö' ‡∂Ω‡∑ô‡∑É ‡∂¥‡∂∏‡∂´‡∂ö‡∑ä ‡∑É‡∂≥‡∑Ñ‡∂±‡∑ä ‡∂ö‡∂ª‡∂±‡∑ä‡∂±."
PRELIMINARY_ANALYSIS_INSTRUCTION = "‡∂î‡∂∂ ‡∑Å‡∑è‡∂ö ‡∂ª‡∑ù‡∂ú ‡∂¥‡∑í‡∑Ö‡∑í‡∂∂‡∂≥ ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω ‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç‡∂•‡∂∫‡∑ô‡∂ö‡∑í. ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫ ‡∑É‡∑Ñ ‡∑Å‡∑è‡∂ö‡∂∫‡∑ö ‡∂±‡∂∏ ‡∂∏‡∂≠ ‡∂¥‡∂Ø‡∂±‡∂∏‡∑ä‡∑Ä, ‡∂ª‡∑ù‡∂ú‡∂∫ ‡∂±‡∑í‡∑Ä‡∑ê‡∂ª‡∂Ø‡∑í‡∑Ä ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂ã‡∂¥‡∂ö‡∑è‡∂ª‡∑ì ‡∑Ä‡∂± ‡∑É‡∂ª‡∂Ω ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± 2-3‡∂ö‡∑ä ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω‡∑ô‡∂±‡∑ä ‡∂Ö‡∑É‡∂±‡∑ä‡∂± (‡∂ö‡∑è‡∂Ω‡∂ú‡∑î‡∂´‡∂∫, ‡∂¢‡∂Ω‡∂∫, ‡∑Ñ‡∑í‡∂ª‡∑î ‡∂ë‡∑Ö‡∑í‡∂∫). ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂†‡∑è‡∂ª‡∂∫ ‡∂∏‡∑ô‡∂∏ ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∂ß *‡∂¥‡∂∏‡∂´‡∂ö‡∑ä* ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±:\n[ANALYSIS]: <‡∂ö‡∑ô‡∂ß‡∑í ‡∂ª‡∑ù‡∂ú ‡∂Ω‡∂ö‡∑ä‡∑Ç‡∂´ ‡∑É‡∑è‡∂ª‡∑è‡∂Ç‡∑Å‡∂∫>\n[QUESTIONS]: <‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫ 1> | <‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫ 2>"
FINAL_ANALYSIS_INSTRUCTION = "‡∂î‡∂∂ ‡∂ã‡∂Ø‡∑ä‡∂∑‡∑í‡∂Ø ‡∑Ä‡∑í‡∂Ø‡∑ä‚Äç‡∂∫‡∑è‡∑Ä ‡∑É‡∑Ñ ‡∑Å‡∑è‡∂ö ‡∂ª‡∑ù‡∂ú ‡∂¥‡∑í‡∑Ö‡∑í‡∂∂‡∂≥ ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω ‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç‡∂•‡∂∫‡∑ô‡∂ö‡∑í. ‡∂î‡∂∂‡∂ß ‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫‡∂ö‡∑ä ‡∑É‡∑Ñ ‡∂¥‡∂ª‡∑í‡∑Å‡∑ì‡∂Ω‡∂ö‡∂∫‡∑è‡∂ú‡∑ö ‡∂¥‡∑è‡∂ª‡∑í‡∑É‡∂ª‡∑í‡∂ö ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î ‡∂Ω‡∑ê‡∂∂‡∑ì ‡∂á‡∂≠. ‡∂∏‡∑ô‡∂∏ ‡∑É‡∑í‡∂∫‡∂Ω‡∑î ‡∂≠‡∑ú‡∂ª‡∂≠‡∑î‡∂ª‡∑î ‡∑É‡∑Ñ ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª, ‡∑É‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∂Ö‡∑Ä‡∑É‡∂±‡∑ä ‡∑Ä‡∑è‡∂ª‡∑ä‡∂≠‡∑è‡∑Ä‡∂ö‡∑ä ‡∑É‡∂¥‡∂∫‡∂±‡∑ä‡∂±: 1. ‡∂ª‡∑ù‡∂ú ‡∑Ä‡∑í‡∂±‡∑í‡∑Å‡∑ä‡∂†‡∂∫ 2. ‡∑Ñ‡∑ö‡∂≠‡∑î 3. ‡∑Ä‡∑í‡∑É‡∂≥‡∑î‡∂∏‡∑ä (‡∂ö‡∑ä‡∑Ç‡∂´‡∑í‡∂ö, ‡∂ö‡∑è‡∂∂‡∂±‡∑í‡∂ö, ‡∂ª‡∑É‡∑è‡∂∫‡∂±‡∑í‡∂ö, ‡∑Ä‡∑ê‡∑Ö‡∑ê‡∂ö‡∑ä‡∑Ä‡∑ì‡∂∏)."
FOLLOW_UP_INSTRUCTION = "‡∂î‡∂∂ ‡∑Å‡∑è‡∂ö ‡∂ª‡∑ù‡∂ú ‡∂¥‡∑í‡∑Ö‡∑í‡∂∂‡∂≥ ‡∂ã‡∂¥‡∂ö‡∑è‡∂ª‡∑Å‡∑ì‡∂Ω‡∑ì ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω ‡∑É‡∑Ñ‡∑è‡∂∫‡∂ö‡∂∫‡∑ô‡∂ö‡∑í. ‡∂¥‡∂ª‡∑í‡∑Å‡∑ì‡∂Ω‡∂ö‡∂∫‡∑è‡∂ß ‡∂Ø‡∑ê‡∂±‡∂ß‡∂∏‡∂≠‡∑ä ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫‡∂ö‡∑ä ‡∂Ω‡∑ê‡∂∂‡∑ì ‡∂á‡∂≠‡∑í ‡∂Ö‡∂≠‡∂ª, ‡∂î‡∑Ä‡∑î‡∂±‡∑ä ‡∂Ø‡∑ê‡∂±‡∑ä ‡∂í ‡∂ú‡∑ê‡∂± ‡∂≠‡∑Ä‡∂≠‡∑ä ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∂Ö‡∑É‡∂∫‡∑í. ‡∑É‡∂∏‡∑ä‡∂¥‡∑ñ‡∂ª‡∑ä‡∂´ ‡∑É‡∂Ç‡∑Ä‡∑è‡∂Ø ‡∂â‡∂≠‡∑í‡∑Ñ‡∑è‡∑É‡∂∫ ‡∑É‡∑Ñ ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª, ‡∂î‡∑Ä‡∑î‡∂±‡∑ä‡∂ú‡∑ö ‡∂±‡∑Ä ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∑Ä‡∂Ω‡∂ß ‡∂ö‡∑ô‡∂ß‡∑í‡∂∫‡∑ô‡∂±‡∑ä ‡∑É‡∑Ñ ‡∂ã‡∂¥‡∂ö‡∑è‡∂ª‡∑Å‡∑ì‡∂Ω‡∑ì‡∑Ä ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±."

# --- 3. ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑É‡∑Ñ Session State ‡∑É‡∑ê‡∂ö‡∑É‡∑ì‡∂∏ ---
@st.cache_resource
def load_models():
    return {
        "identification": genai.GenerativeModel(model_name="gemini-1.5-flash-latest", system_instruction=IDENTIFICATION_INSTRUCTION),
        "preliminary": genai.GenerativeModel(model_name="gemini-1.5-pro-latest", system_instruction=PRELIMINARY_ANALYSIS_INSTRUCTION),
        "final": genai.GenerativeModel(model_name="gemini-1.5-pro-latest", system_instruction=FINAL_ANALYSIS_INSTRUCTION),
        "follow_up": genai.GenerativeModel(model_name="gemini-1.5-pro-latest", system_instruction=FOLLOW_UP_INSTRUCTION)
    }
models = load_models()

def init_session_state():
    # Keep uploader_key and messages across reruns for the same session
    if "uploader_key" not in st.session_state:
        st.session_state.uploader_key = 0
    if "messages" not in st.session_state:
        st.session_state.messages = []
    # Reset other state variables
    st.session_state.stage = "initial" # Stages: initial, awaiting_confirmation, awaiting_info, chat
    st.session_state.plant_name = ""
    st.session_state.initial_analysis = ""
    st.session_state.processed_file_id = None

def reset_conversation():
    # Increment key to force re-render of file uploader
    st.session_state.uploader_key += 1
    init_session_state() # Reset all state variables for a new conversation
    st.rerun()

# Initialize state if it's the first run
if "stage" not in st.session_state:
    init_session_state()

# --- 4. UI ‡∂ö‡∑ú‡∂ß‡∑É ---
st.title("üå± Plant Disease Analyzer")
st.write("‡∂î‡∂∂‡∑ö ‡∑Å‡∑è‡∂ö‡∂∫‡∑ö ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫‡∂ö‡∑ä ‡∂¥‡∑ê‡∂≠‡∑í ‡∂≠‡∑ì‡∂ª‡∑î‡∑Ä‡∑ô‡∂±‡∑ä ‡∂ã‡∂©‡∑î‡∂ú‡∂≠ ‡∂ö‡∂ª ‡∑É‡∂Ç‡∑Ä‡∑è‡∂Ø‡∂∫ ‡∂Ü‡∂ª‡∂∏‡∑ä‡∂∑ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.")

with st.sidebar:
    st.header("‡∂î‡∂∂‡∑ö ‡∑Å‡∑è‡∂ö‡∂∫")
    uploaded_file = st.file_uploader("‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫‡∂ö‡∑ä ‡∂ã‡∂©‡∑î‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±", type=["jpg", "jpeg", "png"], key=f"uploader_{st.session_state.uploader_key}")
    if st.button("‡∂±‡∑Ä ‡∑É‡∂Ç‡∑Ä‡∑è‡∂Ø‡∂∫‡∂ö‡∑ä"):
        reset_conversation()

# --- 5. ‡∂¥‡∑ä‚Äç‡∂ª‡∂∞‡∑è‡∂± ‡∂ö‡∑ä‚Äç‡∂ª‡∑í‡∂∫‡∑è‡∑Ä‡∂Ω‡∑í‡∂∫ ---

# ‡∂±‡∑Ä ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫‡∂ö‡∑ä ‡∂ã‡∂©‡∑î‡∂ú‡∂≠ ‡∂ö‡∑Ö ‡∑Ä‡∑í‡∂ß ‡∑É‡∑í‡∂∫‡∂Ω‡∑ä‡∂Ω ‡∂±‡∑ê‡∑Ä‡∂≠ ‡∑É‡∂ö‡∑É‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
if uploaded_file and uploaded_file.file_id != st.session_state.processed_file_id:
    # A new file is uploaded, reset everything
    init_session_state()
    st.session_state.processed_file_id = uploaded_file.file_id
    image = Image.open(uploaded_file)
    with st.spinner("‡∑Å‡∑è‡∂ö‡∂∫ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∂±‡∑í‡∂∏‡∑í‡∂±‡∑ä ‡∂¥‡∑Ä‡∂≠‡∑ì..."):
        try:
            response = models["identification"].generate_content(image)
            plant_name = response.text.strip()
            if "‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∂≠ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö" in plant_name or not plant_name or len(plant_name.split()) > 3:
                st.error("‡∑É‡∂∏‡∑è‡∑Ä‡∂±‡∑ä‡∂±, ‡∑Å‡∑è‡∂ö‡∂∫ ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í‡∑Ä ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∂≠ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö. ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∑Ä‡∂©‡∑è‡∂≠‡∑ä ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫‡∂ö‡∑ä ‡∂ã‡∂©‡∑î‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.")
                time.sleep(3)
                reset_conversation()
            else:
                st.session_state.plant_name = plant_name
                st.session_state.stage = "awaiting_confirmation"
                st.session_state.messages.append({"role": "assistant", "content": f"‡∂∏‡∑ô‡∂∫ '{st.session_state.plant_name}' ‡∑Å‡∑è‡∂ö‡∂∫‡∂ö‡∑ä‡∂Ø? (‡∂î‡∑Ä‡∑ä / ‡∂±‡∑ê‡∂≠)"})
                st.rerun()
        except Exception as e:
            st.error(f"‡∑Å‡∑è‡∂ö‡∂∫ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∑ö‡∂Ø‡∑ì ‡∂Ø‡∑ù‡∑Ç‡∂∫‡∂ö‡∑ä: {e}")
            time.sleep(3)
            reset_conversation()

# ‡∑É‡∂Ç‡∑Ä‡∑è‡∂Ø ‡∂â‡∂≠‡∑í‡∑Ñ‡∑è‡∑É‡∂∫ ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∑ì‡∂∏
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ‡∂¥‡∂ª‡∑í‡∑Å‡∑ì‡∂Ω‡∂ö ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫ ‡∑Ñ‡∑ê‡∑É‡∑í‡∂ª‡∑Ä‡∑ì‡∂∏
if prompt := st.chat_input("‡∂î‡∂∂‡∑ö ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª ‡∂∏‡∑ô‡∑Ñ‡∑í ‡∂á‡∂≠‡∑î‡∑Ö‡∂≠‡∑ä ‡∂ö‡∂ª‡∂±‡∑ä‡∂±..."):
    if not st.session_state.processed_file_id:
        st.warning("‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂¥‡∑Ö‡∂∏‡∑î‡∑Ä ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫‡∂ö‡∑ä ‡∂ã‡∂©‡∑î‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±."); st.stop()

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    # --- ‡∂≠‡∑è‡∂ª‡∑ä‡∂ö‡∑í‡∂ö ‡∂¥‡∑ä‚Äç‡∂ª‡∑Ä‡∑è‡∑Ñ‡∂∫ (Logic Flow) ---
    current_stage = st.session_state.stage
    image = Image.open(uploaded_file)

    # ‡∂Ö‡∂Ø‡∑í‡∂∫‡∂ª 1: ‡∑Å‡∑è‡∂ö‡∂∫‡∑ö ‡∂±‡∂∏ ‡∂≠‡∑Ñ‡∑Ä‡∑î‡∂ª‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
    if current_stage == "awaiting_confirmation":
        if any(word in prompt.lower() for word in ["‡∂î‡∑Ä‡∑ä", "‡∂î‡∑Ä‡∑î", "ow", "yes"]):
            with st.spinner("‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫ ‡∂ö‡∂ª‡∂∏‡∑í‡∂±‡∑ä..."):
                response = models["preliminary"].generate_content([f"‡∂∏‡∑ô‡∂∫ {st.session_state.plant_name} ‡∑Å‡∑è‡∂ö‡∂∫‡∂ö‡∑í.", image])
                analysis_match = re.search(r"\[ANALYSIS\]:\s*(.*?)\s*\n\[QUESTIONS\]:", response.text, re.DOTALL)
                questions_match = re.search(r"\[QUESTIONS\]:\s*(.*)", response.text, re.DOTALL)

                if analysis_match and questions_match:
                    st.session_state.initial_analysis = analysis_match.group(1).strip()
                    questions = questions_match.group(1).strip().replace(" | ", "\n- ")
                    msg = (f"‡∑Ñ‡∑ú‡∂≥‡∂∫‡∑í. ‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∂±‡∑í‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∂´‡∂∫‡∂ß ‡∂Ö‡∂±‡∑î‡∑Ä, {st.session_state.initial_analysis.lower()}.\n\n"
                           f"‡∂ª‡∑ù‡∂ú‡∂∫ ‡∂±‡∑í‡∑Ä‡∑ê‡∂ª‡∂Ø‡∑í‡∑Ä ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß, ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂∏‡∑ô‡∂∏ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∑Ä‡∂Ω‡∂ß ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±:\n- {questions}")
                    st.session_state.messages.append({"role": "assistant", "content": msg})
                    st.session_state.stage = "awaiting_info"
                    st.rerun()
                else:
                    st.error("‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ö‡∂Ø‡∑ì ‡∂Ø‡∑ù‡∑Ç‡∂∫‡∂ö‡∑ä. ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂±‡∑ê‡∑Ä‡∂≠ ‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.")
        else:
            reset_conversation()

    # ‡∂Ö‡∂Ø‡∑í‡∂∫‡∂ª 2: ‡∂Ö‡∑Ä‡∑É‡∂±‡∑ä ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´ ‡∑Ä‡∑è‡∂ª‡∑ä‡∂≠‡∑è‡∑Ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ì‡∂∏
    elif current_stage == "awaiting_info":
        with st.chat_message("assistant"):
            final_prompt = (f"‡∑Å‡∑è‡∂ö‡∂∫: {st.session_state.plant_name}.\n"
                            f"‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∂ª‡∑ù‡∂ú ‡∂Ω‡∂ö‡∑ä‡∑Ç‡∂´: {st.session_state.initial_analysis}.\n"
                            f"‡∂¥‡∂ª‡∑í‡∑Å‡∑ì‡∂Ω‡∂ö‡∂∫‡∑è‡∂ú‡∑ö ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î: {prompt}\n\n"
                            "‡∂â‡∑Ñ‡∂≠ ‡∂≠‡∑ú‡∂ª‡∂≠‡∑î‡∂ª‡∑î ‡∑É‡∑Ñ ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫ ‡∂∏‡∂≠ ‡∂¥‡∂Ø‡∂±‡∂∏‡∑ä‡∑Ä ‡∑É‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∑è‡∂≠‡∑ä‡∂∏‡∂ö, ‡∂Ö‡∑Ä‡∑É‡∂±‡∑ä ‡∑Ä‡∑è‡∂ª‡∑ä‡∂≠‡∑è‡∑Ä ‡∑É‡∂¥‡∂∫‡∂±‡∑ä‡∂±.")
            response_stream = models["final"].generate_content([final_prompt, image], stream=True)
            full_response = st.write_stream(response_stream)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.session_state.stage = "chat" # <<< ‡∂Ö‡∂õ‡∂´‡∑ä‡∂© ‡∑É‡∂Ç‡∑Ä‡∑è‡∂Ø‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂∫‡∂≠‡∑î‡∂ª!
            st.rerun()

    # ‡∂Ö‡∂Ø‡∑í‡∂∫‡∂ª 3: ‡∂Ö‡∂õ‡∂´‡∑ä‡∂© ‡∑É‡∂Ç‡∑Ä‡∑è‡∂Ø‡∂∫ (Follow-up Chat)
    elif current_stage == "chat":
        with st.chat_message("assistant"):
            history_for_model = [{"role": "model" if msg["role"] == "assistant" else "user", "parts": [msg["content"]]} for msg in st.session_state.messages[:-1]]
            chat = models["follow_up"].start_chat(history=history_for_model)
            response_stream = chat.send_message([prompt, image], stream=True)
            full_response = st.write_stream(response_stream)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.rerun()

st.divider()
st.caption("‚ö†Ô∏è ‡∂∏‡∑ô‡∂∏ AI ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫ ‡∑Ä‡∑ò‡∂≠‡∑ä‡∂≠‡∑ì‡∂∫ ‡∂ö‡∑ò‡∑Ç‡∑í‡∂ö‡∑è‡∂ª‡∑ä‡∂∏‡∑í‡∂ö ‡∂ã‡∂¥‡∂Ø‡∑ô‡∑É‡∑ä ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂Ü‡∂Ø‡∑ö‡∑Å‡∂ö‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑ö.")